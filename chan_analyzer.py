# -*- coding: utf-8 -*-
"""
===================================
ç¼ è®ºåˆ†æå™¨ - ç¼ ä¸­è¯´ç¦…æŠ€æœ¯åˆ†æ
===================================

ç¼ è®ºæ ¸å¿ƒæ¦‚å¿µï¼š
1. åˆ†å‹ï¼šé¡¶åˆ†å‹ï¼ˆä¸­é—´Kçº¿æœ€é«˜ï¼‰ã€åº•åˆ†å‹ï¼ˆä¸­é—´Kçº¿æœ€ä½ï¼‰
2. ç¬”ï¼šè¿æ¥ç›¸é‚»åˆ†å‹ï¼Œé¡¶â†’åº•ä¸ºä¸‹è·Œç¬”ï¼Œåº•â†’é¡¶ä¸ºä¸Šæ¶¨ç¬”
3. çº¿æ®µï¼šè‡³å°‘3ç¬”æ„æˆçš„æ›´é«˜çº§åˆ«èµ°åŠ¿
4. ä¸­æ¢ï¼šè‡³å°‘3ç¬”é‡å åŒºåŸŸï¼ˆZGä¸­æ¢ä¸Šæ²¿ã€ZDä¸­æ¢ä¸‹æ²¿ï¼‰
5. èƒŒé©°ï¼šMACDè¾…åŠ©åˆ¤æ–­è¶‹åŠ¿åŠ›åº¦è¡°å‡
6. ä¹°å–ç‚¹ï¼š
   - ä¸€ä¹°ï¼šä¸‹è·Œè¶‹åŠ¿èƒŒé©°åçš„ç¬¬ä¸€ä¸ªä¹°ç‚¹
   - äºŒä¹°ï¼šå›è¸©ä¸ç ´ä¸€ä¹°ä½ç‚¹
   - ä¸‰ä¹°ï¼šç¦»å¼€ä¸­æ¢åå›è¸©ä¸è¿›ä¸­æ¢
   - ä¸€å–ã€äºŒå–ã€ä¸‰å–åŒç†

ä½¿ç”¨æ–¹å¼ï¼š
    analyzer = ChanAnalyzer()
    result = analyzer.analyze(df, '000001')
"""

import logging
from dataclasses import dataclass, field
from typing import Optional, List, Dict, Any, Tuple
from enum import Enum

import pandas as pd
import numpy as np

logger = logging.getLogger(__name__)


class FenXingType(Enum):
    """åˆ†å‹ç±»å‹"""
    TOP = "é¡¶åˆ†å‹"      # ä¸­é—´Kçº¿é«˜ç‚¹æœ€é«˜
    BOTTOM = "åº•åˆ†å‹"   # ä¸­é—´Kçº¿ä½ç‚¹æœ€ä½
    NONE = "æ— åˆ†å‹"


class BiDirection(Enum):
    """ç¬”æ–¹å‘"""
    UP = "ä¸Šå‡ç¬”"       # åº•åˆ†å‹ â†’ é¡¶åˆ†å‹
    DOWN = "ä¸‹é™ç¬”"     # é¡¶åˆ†å‹ â†’ åº•åˆ†å‹


class XianDuanDirection(Enum):
    """çº¿æ®µæ–¹å‘"""
    UP = "ä¸Šå‡çº¿æ®µ"
    DOWN = "ä¸‹é™çº¿æ®µ"


class TrendType(Enum):
    """èµ°åŠ¿ç±»å‹"""
    UP_TREND = "ä¸Šæ¶¨è¶‹åŠ¿"      # ä¸­æ¢ä¾æ¬¡å‡é«˜
    DOWN_TREND = "ä¸‹è·Œè¶‹åŠ¿"    # ä¸­æ¢ä¾æ¬¡é™ä½
    CONSOLIDATION = "ç›˜æ•´"    # åªæœ‰ä¸€ä¸ªä¸­æ¢


class BeiChiType(Enum):
    """èƒŒé©°ç±»å‹"""
    TREND_BEICHI = "è¶‹åŠ¿èƒŒé©°"     # ä¸¤ä¸ªåŒå‘èµ°åŠ¿æ®µå¯¹æ¯”
    PAN_ZHENG_BEICHI = "ç›˜æ•´èƒŒé©°" # åŒä¸€ä¸­æ¢å†…å¯¹æ¯”
    NONE = "æ— èƒŒé©°"


class BuySellPoint(Enum):
    """ä¹°å–ç‚¹ç±»å‹"""
    BUY_1 = "ä¸€ä¹°"    # è¶‹åŠ¿èƒŒé©°å
    BUY_2 = "äºŒä¹°"    # å›è¸©ä¸ç ´ä¸€ä¹°ä½ç‚¹
    BUY_3 = "ä¸‰ä¹°"    # ç¦»å¼€ä¸­æ¢åå›è¸©ä¸è¿›ä¸­æ¢
    SELL_1 = "ä¸€å–"   # è¶‹åŠ¿èƒŒé©°å
    SELL_2 = "äºŒå–"   # åå¼¹ä¸ç ´ä¸€å–é«˜ç‚¹
    SELL_3 = "ä¸‰å–"   # ç¦»å¼€ä¸­æ¢ååå¼¹ä¸è¿›ä¸­æ¢
    NONE = "æ— ä¹°å–ç‚¹"


@dataclass
class FenXing:
    """åˆ†å‹æ•°æ®ç±»"""
    index: int              # åœ¨DataFrameä¸­çš„ç´¢å¼•
    type: FenXingType       # åˆ†å‹ç±»å‹
    high: float             # åˆ†å‹é«˜ç‚¹ï¼ˆé¡¶åˆ†å‹å–æœ€é«˜ï¼‰
    low: float              # åˆ†å‹ä½ç‚¹ï¼ˆåº•åˆ†å‹å–æœ€ä½ï¼‰
    date: str               # æ—¥æœŸ
    fx_value: float = 0.0   # åˆ†å‹å€¼ï¼ˆé¡¶åˆ†å‹=highï¼Œåº•åˆ†å‹=lowï¼‰
    
    def __post_init__(self):
        if self.type == FenXingType.TOP:
            self.fx_value = self.high
        elif self.type == FenXingType.BOTTOM:
            self.fx_value = self.low


@dataclass
class Bi:
    """ç¬”æ•°æ®ç±»"""
    start_fx: FenXing       # èµ·å§‹åˆ†å‹
    end_fx: FenXing         # ç»“æŸåˆ†å‹
    direction: BiDirection  # ç¬”æ–¹å‘
    high: float = 0.0       # ç¬”çš„æœ€é«˜ç‚¹
    low: float = 0.0        # ç¬”çš„æœ€ä½ç‚¹
    power: float = 0.0      # ç¬”çš„åŠ›åº¦ï¼ˆMACDé¢ç§¯ï¼‰
    
    def __post_init__(self):
        self.high = max(self.start_fx.high, self.end_fx.high)
        self.low = min(self.start_fx.low, self.end_fx.low)


@dataclass
class ZhongShu:
    """ä¸­æ¢æ•°æ®ç±»"""
    bis: List[Bi]           # ç»„æˆä¸­æ¢çš„ç¬”
    zg: float               # ä¸­æ¢ä¸Šæ²¿ï¼ˆZGï¼‰
    zd: float               # ä¸­æ¢ä¸‹æ²¿ï¼ˆZDï¼‰
    gg: float               # ä¸­æ¢é«˜é«˜ç‚¹
    dd: float               # ä¸­æ¢ä½ä½ç‚¹
    direction: Optional[BiDirection] = None  # ä¸­æ¢å½¢æˆæ–¹å‘
    
    @property
    def range(self) -> float:
        """ä¸­æ¢åŒºé—´"""
        return self.zg - self.zd
    
    @property
    def center(self) -> float:
        """ä¸­æ¢ä¸­å¿ƒç‚¹"""
        return (self.zg + self.zd) / 2


@dataclass
class XianDuan:
    """çº¿æ®µæ•°æ®ç±»"""
    bis: List[Bi]           # ç»„æˆçº¿æ®µçš„ç¬”
    direction: XianDuanDirection  # çº¿æ®µæ–¹å‘
    high: float = 0.0       # çº¿æ®µæœ€é«˜ç‚¹
    low: float = 0.0        # çº¿æ®µæœ€ä½ç‚¹
    
    def __post_init__(self):
        if self.bis:
            self.high = max(bi.high for bi in self.bis)
            self.low = min(bi.low for bi in self.bis)


@dataclass
class ChanAnalysisResult:
    """ç¼ è®ºåˆ†æç»“æœ"""
    code: str
    
    # === åˆ†å‹ä¿¡æ¯ ===
    fenxings: List[FenXing] = field(default_factory=list)
    last_fenxing: Optional[FenXing] = None    # æœ€è¿‘çš„åˆ†å‹
    fenxing_summary: str = ""                  # åˆ†å‹æ‘˜è¦
    
    # === ç¬”ä¿¡æ¯ ===
    bis: List[Bi] = field(default_factory=list)
    last_bi: Optional[Bi] = None              # æœ€è¿‘çš„ç¬”
    bi_summary: str = ""                       # ç¬”æ‘˜è¦
    current_bi_direction: str = ""            # å½“å‰ç¬”æ–¹å‘
    
    # === çº¿æ®µä¿¡æ¯ ===
    xianduans: List[XianDuan] = field(default_factory=list)
    last_xianduan: Optional[XianDuan] = None  # æœ€è¿‘çš„çº¿æ®µ
    xianduan_summary: str = ""                 # çº¿æ®µæ‘˜è¦
    
    # === ä¸­æ¢ä¿¡æ¯ ===
    zhongshus: List[ZhongShu] = field(default_factory=list)
    current_zhongshu: Optional[ZhongShu] = None  # å½“å‰ä¸­æ¢
    zhongshu_summary: str = ""                   # ä¸­æ¢æ‘˜è¦
    price_position: str = ""                     # ä»·æ ¼ç›¸å¯¹ä¸­æ¢ä½ç½®
    
    # === èƒŒé©°ä¿¡æ¯ ===
    beichi_type: BeiChiType = BeiChiType.NONE
    beichi_summary: str = ""
    macd_divergence: bool = False              # MACDæ˜¯å¦èƒŒç¦»
    
    # === ä¹°å–ç‚¹ ===
    buy_sell_point: BuySellPoint = BuySellPoint.NONE
    buy_sell_reason: str = ""
    
    # === è¶‹åŠ¿åˆ¤æ–­ ===
    trend_type: TrendType = TrendType.CONSOLIDATION
    trend_summary: str = ""
    
    # === ç»¼åˆåˆ†æ ===
    chan_score: int = 50                       # ç¼ è®ºè¯„åˆ† 0-100
    operation_suggestion: str = ""             # æ“ä½œå»ºè®®
    key_levels: Dict[str, float] = field(default_factory=dict)  # å…³é”®ç‚¹ä½
    analysis_summary: str = ""                 # ç»¼åˆåˆ†ææ‘˜è¦
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'code': self.code,
            # åˆ†å‹
            'fenxing_count': len(self.fenxings),
            'last_fenxing': self.last_fenxing.type.value if self.last_fenxing else 'æ— ',
            'fenxing_summary': self.fenxing_summary,
            # ç¬”
            'bi_count': len(self.bis),
            'current_bi_direction': self.current_bi_direction,
            'bi_summary': self.bi_summary,
            # çº¿æ®µ
            'xianduan_count': len(self.xianduans),
            'xianduan_summary': self.xianduan_summary,
            # ä¸­æ¢
            'zhongshu_count': len(self.zhongshus),
            'zhongshu_summary': self.zhongshu_summary,
            'price_position': self.price_position,
            'current_zg': self.current_zhongshu.zg if self.current_zhongshu else 0,
            'current_zd': self.current_zhongshu.zd if self.current_zhongshu else 0,
            # èƒŒé©°
            'beichi_type': self.beichi_type.value,
            'beichi_summary': self.beichi_summary,
            'macd_divergence': self.macd_divergence,
            # ä¹°å–ç‚¹
            'buy_sell_point': self.buy_sell_point.value,
            'buy_sell_reason': self.buy_sell_reason,
            # è¶‹åŠ¿
            'trend_type': self.trend_type.value,
            'trend_summary': self.trend_summary,
            # ç»¼åˆ
            'chan_score': self.chan_score,
            'operation_suggestion': self.operation_suggestion,
            'key_levels': self.key_levels,
            'analysis_summary': self.analysis_summary,
        }


class ChanAnalyzer:
    """
    ç¼ è®ºåˆ†æå™¨
    
    åŸºäºç¼ ä¸­è¯´ç¦…ç†è®ºè¿›è¡ŒæŠ€æœ¯åˆ†æï¼š
    1. è¯†åˆ«åˆ†å‹ï¼ˆé¡¶åˆ†å‹ã€åº•åˆ†å‹ï¼‰
    2. æ„å»ºç¬”ï¼ˆè¿æ¥åˆ†å‹ï¼‰
    3. è¯†åˆ«çº¿æ®µ
    4. å®šä½ä¸­æ¢
    5. åˆ¤æ–­èƒŒé©°
    6. ç¡®å®šä¹°å–ç‚¹
    """
    
    # åˆ†å‹ä¹‹é—´æœ€å°‘Kçº¿æ•°ï¼ˆæ ‡å‡†ç¼ è®ºè¦æ±‚è‡³å°‘1æ ¹ç‹¬ç«‹Kçº¿ï¼‰
    MIN_K_BETWEEN_FX = 4  # ä½¿ç”¨4ä½œä¸ºæ ‡å‡†ï¼ˆåŒ…å«åˆ†å‹æœ¬èº«3æ ¹ï¼‰
    
    def __init__(self, strict_mode: bool = False):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            strict_mode: æ˜¯å¦ä½¿ç”¨ä¸¥æ ¼æ¨¡å¼ï¼ˆæ›´ä¸¥æ ¼çš„åˆ†å‹ç¡®è®¤ï¼‰
        """
        self.strict_mode = strict_mode
    
    def analyze(self, df: pd.DataFrame, code: str) -> ChanAnalysisResult:
        """
        åˆ†æè‚¡ç¥¨çš„ç¼ è®ºå½¢æ€
        
        Args:
            df: åŒ…å« OHLCV æ•°æ®çš„ DataFrame
            code: è‚¡ç¥¨ä»£ç 
            
        Returns:
            ChanAnalysisResult åˆ†æç»“æœ
        """
        result = ChanAnalysisResult(code=code)
        
        if df is None or df.empty or len(df) < 10:
            logger.warning(f"[{code}] æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œç¼ è®ºåˆ†æ")
            result.analysis_summary = "æ•°æ®ä¸è¶³ï¼Œæ— æ³•å®Œæˆç¼ è®ºåˆ†æ"
            return result
        
        # ç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸæ’åº
        df = df.sort_values('date').reset_index(drop=True)
        
        # 1. Kçº¿åŒ…å«å¤„ç†ï¼ˆåˆå¹¶åŒ…å«å…³ç³»ï¼‰
        df_processed = self._process_include(df)
        
        # 2. è®¡ç®—MACDï¼ˆç”¨äºèƒŒé©°åˆ¤æ–­ï¼‰
        df_processed = self._calculate_macd(df_processed)
        
        # 3. è¯†åˆ«åˆ†å‹
        fenxings = self._identify_fenxing(df_processed)
        result.fenxings = fenxings
        if fenxings:
            result.last_fenxing = fenxings[-1]
            result.fenxing_summary = self._summarize_fenxings(fenxings)
        
        # 4. æ„å»ºç¬”
        bis = self._build_bi(fenxings, df_processed)
        result.bis = bis
        if bis:
            result.last_bi = bis[-1]
            result.current_bi_direction = bis[-1].direction.value
            result.bi_summary = self._summarize_bis(bis)
        
        # 5. è¯†åˆ«çº¿æ®µ
        xianduans = self._build_xianduan(bis)
        result.xianduans = xianduans
        if xianduans:
            result.last_xianduan = xianduans[-1]
            result.xianduan_summary = self._summarize_xianduans(xianduans)
        
        # 6. å®šä½ä¸­æ¢
        zhongshus = self._identify_zhongshu(bis)
        result.zhongshus = zhongshus
        if zhongshus:
            result.current_zhongshu = zhongshus[-1]
            current_price = float(df.iloc[-1]['close'])
            result.price_position = self._get_price_position(current_price, zhongshus[-1])
            result.zhongshu_summary = self._summarize_zhongshu(zhongshus[-1], current_price)
        
        # 7. åˆ¤æ–­èƒŒé©°
        beichi_type, beichi_summary, macd_div = self._check_beichi(bis, df_processed)
        result.beichi_type = beichi_type
        result.beichi_summary = beichi_summary
        result.macd_divergence = macd_div
        
        # 8. åˆ¤æ–­è¶‹åŠ¿
        result.trend_type, result.trend_summary = self._analyze_trend(zhongshus, bis)
        
        # 9. ç¡®å®šä¹°å–ç‚¹
        result.buy_sell_point, result.buy_sell_reason = self._identify_buy_sell_point(
            result, df_processed
        )
        
        # 10. è®¡ç®—å…³é”®ç‚¹ä½
        result.key_levels = self._calculate_key_levels(result, df_processed)
        
        # 11. ç»¼åˆè¯„åˆ†å’Œå»ºè®®
        result.chan_score = self._calculate_score(result)
        result.operation_suggestion = self._generate_suggestion(result)
        result.analysis_summary = self._generate_summary(result)
        
        return result
    
    def _process_include(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Kçº¿åŒ…å«å¤„ç†
        
        åŒ…å«å…³ç³»ï¼šå½“ä¸¤æ ¹Kçº¿é«˜ä½ç‚¹å­˜åœ¨åŒ…å«å…³ç³»æ—¶ï¼Œåˆå¹¶ä¸ºä¸€æ ¹
        - ä¸Šæ¶¨ä¸­å–é«˜é«˜ã€ä½é«˜
        - ä¸‹è·Œä¸­å–ä½ä½ã€é«˜ä½
        """
        df = df.copy()
        
        # æ·»åŠ å¤„ç†åçš„é«˜ä½ç‚¹åˆ—
        df['high_p'] = df['high'].astype(float)
        df['low_p'] = df['low'].astype(float)
        
        # å¤„ç†åŒ…å«å…³ç³»
        i = 1
        while i < len(df):
            prev_high = df.loc[df.index[i-1], 'high_p']
            prev_low = df.loc[df.index[i-1], 'low_p']
            curr_high = df.loc[df.index[i], 'high_p']
            curr_low = df.loc[df.index[i], 'low_p']
            
            # åˆ¤æ–­åŒ…å«å…³ç³»
            is_include = (
                (prev_high >= curr_high and prev_low <= curr_low) or
                (curr_high >= prev_high and curr_low <= prev_low)
            )
            
            if is_include:
                # åˆ¤æ–­æ–¹å‘ï¼ˆé€šè¿‡å‰ä¸¤æ ¹Kçº¿çš„è¶‹åŠ¿ï¼‰
                if i >= 2:
                    prev2_high = df.loc[df.index[i-2], 'high_p']
                    is_up = prev_high > prev2_high
                else:
                    is_up = curr_high > prev_high
                
                if is_up:
                    # ä¸Šæ¶¨ä¸­å–é«˜é«˜ã€ä½é«˜
                    new_high = max(prev_high, curr_high)
                    new_low = max(prev_low, curr_low)
                else:
                    # ä¸‹è·Œä¸­å–ä½ä½ã€é«˜ä½
                    new_high = min(prev_high, curr_high)
                    new_low = min(prev_low, curr_low)
                
                df.loc[df.index[i], 'high_p'] = new_high
                df.loc[df.index[i], 'low_p'] = new_low
            
            i += 1
        
        return df
    
    def _calculate_macd(self, df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—MACDæŒ‡æ ‡"""
        df = df.copy()
        
        close = df['close'].astype(float)
        
        # EMAè®¡ç®—
        ema12 = close.ewm(span=12, adjust=False).mean()
        ema26 = close.ewm(span=26, adjust=False).mean()
        
        # DIF
        df['macd_dif'] = ema12 - ema26
        
        # DEA (ä¿¡å·çº¿)
        df['macd_dea'] = df['macd_dif'].ewm(span=9, adjust=False).mean()
        
        # MACDæŸ±
        df['macd_bar'] = 2 * (df['macd_dif'] - df['macd_dea'])
        
        return df
    
    def _identify_fenxing(self, df: pd.DataFrame) -> List[FenXing]:
        """
        è¯†åˆ«åˆ†å‹
        
        é¡¶åˆ†å‹ï¼šä¸­é—´Kçº¿é«˜ç‚¹æ¯”å‰åéƒ½é«˜
        åº•åˆ†å‹ï¼šä¸­é—´Kçº¿ä½ç‚¹æ¯”å‰åéƒ½ä½
        """
        fenxings = []
        
        for i in range(1, len(df) - 1):
            prev_high = df.loc[df.index[i-1], 'high_p']
            curr_high = df.loc[df.index[i], 'high_p']
            next_high = df.loc[df.index[i+1], 'high_p']
            
            prev_low = df.loc[df.index[i-1], 'low_p']
            curr_low = df.loc[df.index[i], 'low_p']
            next_low = df.loc[df.index[i+1], 'low_p']
            
            date_val = df.loc[df.index[i], 'date']
            if hasattr(date_val, 'strftime'):
                date_str = date_val.strftime('%Y-%m-%d')
            else:
                date_str = str(date_val)
            
            # é¡¶åˆ†å‹åˆ¤æ–­
            if curr_high > prev_high and curr_high > next_high:
                fx = FenXing(
                    index=i,
                    type=FenXingType.TOP,
                    high=float(curr_high),
                    low=float(curr_low),
                    date=date_str
                )
                fenxings.append(fx)
            
            # åº•åˆ†å‹åˆ¤æ–­
            elif curr_low < prev_low and curr_low < next_low:
                fx = FenXing(
                    index=i,
                    type=FenXingType.BOTTOM,
                    high=float(curr_high),
                    low=float(curr_low),
                    date=date_str
                )
                fenxings.append(fx)
        
        # è¿‡æ»¤ï¼šç›¸é‚»åˆ†å‹å¿…é¡»æ˜¯é¡¶åº•äº¤æ›¿
        filtered = self._filter_fenxing(fenxings)
        
        return filtered
    
    def _filter_fenxing(self, fenxings: List[FenXing]) -> List[FenXing]:
        """
        è¿‡æ»¤åˆ†å‹ï¼Œç¡®ä¿é¡¶åº•äº¤æ›¿
        
        å¦‚æœå‡ºç°è¿ç»­é¡¶åˆ†å‹ï¼Œå–æœ€é«˜çš„
        å¦‚æœå‡ºç°è¿ç»­åº•åˆ†å‹ï¼Œå–æœ€ä½çš„
        """
        if not fenxings:
            return []
        
        filtered = [fenxings[0]]
        
        for fx in fenxings[1:]:
            last = filtered[-1]
            
            if fx.type == last.type:
                # åŒç±»å‹åˆ†å‹ï¼Œå–æå€¼
                if fx.type == FenXingType.TOP:
                    if fx.high > last.high:
                        filtered[-1] = fx
                else:  # BOTTOM
                    if fx.low < last.low:
                        filtered[-1] = fx
            else:
                # ä¸åŒç±»å‹ï¼Œæ£€æŸ¥æ˜¯å¦æ»¡è¶³æœ€å°Kçº¿é—´éš”
                if fx.index - last.index >= self.MIN_K_BETWEEN_FX:
                    filtered.append(fx)
                else:
                    # é—´éš”å¤ªè¿‘ï¼Œä¿ç•™æ›´æç«¯çš„
                    if fx.type == FenXingType.TOP and fx.high > last.low:
                        # é¡¶åˆ†å‹é«˜äºå‰åº•åˆ†å‹ä½ç‚¹ï¼Œå¯èƒ½å½¢æˆæœ‰æ•ˆç¬”
                        pass  # æš‚æ—¶ä¸å¤„ç†
        
        return filtered
    
    def _build_bi(self, fenxings: List[FenXing], df: pd.DataFrame) -> List[Bi]:
        """
        æ„å»ºç¬”
        
        è¿æ¥ç›¸é‚»çš„é¡¶åº•åˆ†å‹å½¢æˆç¬”
        """
        bis = []
        
        if len(fenxings) < 2:
            return bis
        
        for i in range(len(fenxings) - 1):
            start_fx = fenxings[i]
            end_fx = fenxings[i + 1]
            
            # ç¡®å®šç¬”æ–¹å‘
            if start_fx.type == FenXingType.BOTTOM and end_fx.type == FenXingType.TOP:
                direction = BiDirection.UP
            elif start_fx.type == FenXingType.TOP and end_fx.type == FenXingType.BOTTOM:
                direction = BiDirection.DOWN
            else:
                continue  # æ— æ•ˆçš„åˆ†å‹ç»„åˆ
            
            # è®¡ç®—ç¬”çš„MACDåŠ›åº¦ï¼ˆé¢ç§¯ï¼‰
            power = self._calculate_bi_power(start_fx.index, end_fx.index, df)
            
            bi = Bi(
                start_fx=start_fx,
                end_fx=end_fx,
                direction=direction,
                power=power
            )
            bis.append(bi)
        
        return bis
    
    def _calculate_bi_power(self, start_idx: int, end_idx: int, df: pd.DataFrame) -> float:
        """è®¡ç®—ç¬”çš„MACDåŠ›åº¦ï¼ˆé¢ç§¯ï¼‰"""
        if 'macd_bar' not in df.columns:
            return 0.0
        
        try:
            macd_slice = df.loc[start_idx:end_idx, 'macd_bar']
            return abs(macd_slice.sum())
        except:
            return 0.0
    
    def _build_xianduan(self, bis: List[Bi]) -> List[XianDuan]:
        """
        æ„å»ºçº¿æ®µ
        
        çº¿æ®µç”±è‡³å°‘3ç¬”æ„æˆï¼Œä¸”è¦æ»¡è¶³ç‰¹å¾åºåˆ—çš„ç ´å
        ç®€åŒ–ç‰ˆï¼šæ¯3ç¬”æ„æˆä¸€ä¸ªçº¿æ®µ
        """
        xianduans = []
        
        if len(bis) < 3:
            return xianduans
        
        i = 0
        while i < len(bis) - 2:
            # å–è¿ç»­3ç¬”
            segment_bis = bis[i:i+3]
            
            # ç¡®å®šçº¿æ®µæ–¹å‘ï¼ˆä»¥ç¬¬ä¸€ç¬”æ–¹å‘ä¸ºå‡†ï¼‰
            first_bi = segment_bis[0]
            if first_bi.direction == BiDirection.UP:
                direction = XianDuanDirection.UP
            else:
                direction = XianDuanDirection.DOWN
            
            xd = XianDuan(
                bis=segment_bis,
                direction=direction
            )
            xianduans.append(xd)
            
            i += 2  # æ­¥è¿›2ï¼Œå…è®¸çº¿æ®µæœ‰é‡å 
        
        return xianduans
    
    def _identify_zhongshu(self, bis: List[Bi]) -> List[ZhongShu]:
        """
        è¯†åˆ«ä¸­æ¢
        
        ä¸­æ¢å®šä¹‰ï¼šè‡³å°‘3ç¬”çš„é‡å åŒºåŸŸ
        ZG = min(å„ç¬”é«˜ç‚¹)
        ZD = max(å„ç¬”ä½ç‚¹)
        å¦‚æœ ZG > ZDï¼Œåˆ™å½¢æˆæœ‰æ•ˆä¸­æ¢
        """
        zhongshus = []
        
        if len(bis) < 3:
            return zhongshus
        
        i = 0
        while i < len(bis) - 2:
            # å°è¯•ä»å½“å‰ä½ç½®æ„å»ºä¸­æ¢
            zg = min(bis[i].high, bis[i+1].high, bis[i+2].high)
            zd = max(bis[i].low, bis[i+1].low, bis[i+2].low)
            
            if zg > zd:  # æœ‰æ•ˆä¸­æ¢
                # è®¡ç®—ä¸­æ¢çš„å®Œæ•´èŒƒå›´
                zs_bis = [bis[i], bis[i+1], bis[i+2]]
                gg = max(bi.high for bi in zs_bis)
                dd = min(bi.low for bi in zs_bis)
                
                # å°è¯•æ‰©å±•ä¸­æ¢ï¼ˆåŠ å…¥åç»­æ»¡è¶³æ¡ä»¶çš„ç¬”ï¼‰
                j = i + 3
                while j < len(bis):
                    new_zg = min(zg, bis[j].high)
                    new_zd = max(zd, bis[j].low)
                    
                    if new_zg > new_zd:
                        # å¯ä»¥æ‰©å±•
                        zg = new_zg
                        zd = new_zd
                        zs_bis.append(bis[j])
                        gg = max(gg, bis[j].high)
                        dd = min(dd, bis[j].low)
                        j += 1
                    else:
                        break
                
                zs = ZhongShu(
                    bis=zs_bis,
                    zg=zg,
                    zd=zd,
                    gg=gg,
                    dd=dd,
                    direction=bis[i].direction
                )
                zhongshus.append(zs)
                
                i = j  # è·³è¿‡å·²æ„å»ºä¸­æ¢çš„ç¬”
            else:
                i += 1
        
        return zhongshus
    
    def _get_price_position(self, price: float, zs: ZhongShu) -> str:
        """è·å–ä»·æ ¼ç›¸å¯¹ä¸­æ¢çš„ä½ç½®"""
        if price > zs.zg:
            pct = (price - zs.zg) / zs.zg * 100
            return f"ä¸­æ¢ä¸Šæ–¹ (+{pct:.1f}%)"
        elif price < zs.zd:
            pct = (zs.zd - price) / zs.zd * 100
            return f"ä¸­æ¢ä¸‹æ–¹ (-{pct:.1f}%)"
        else:
            # åœ¨ä¸­æ¢å†…ï¼Œè®¡ç®—ä½ç½®
            range_pct = (price - zs.zd) / (zs.zg - zs.zd) * 100
            return f"ä¸­æ¢å†… ({range_pct:.0f}%ä½ç½®)"
    
    def _check_beichi(
        self, 
        bis: List[Bi], 
        df: pd.DataFrame
    ) -> Tuple[BeiChiType, str, bool]:
        """
        åˆ¤æ–­èƒŒé©°
        
        èƒŒé©°ç±»å‹ï¼š
        1. è¶‹åŠ¿èƒŒé©°ï¼šä¸¤æ®µåŒå‘èµ°åŠ¿ï¼Œåä¸€æ®µåŠ›åº¦å¼±äºå‰ä¸€æ®µ
        2. ç›˜æ•´èƒŒé©°ï¼šåŒä¸€ä¸­æ¢å†…ï¼Œåä¸€æ®µåŠ›åº¦å¼±äºå‰ä¸€æ®µ
        
        é€šè¿‡MACDé¢ç§¯å¯¹æ¯”åˆ¤æ–­
        """
        if len(bis) < 5:
            return BeiChiType.NONE, "ç¬”æ•°ä¸è¶³ï¼Œæ— æ³•åˆ¤æ–­èƒŒé©°", False
        
        # å–æœ€å5ç¬”è¿›è¡Œåˆ†æ
        recent_bis = bis[-5:]
        
        # æ£€æŸ¥åŒå‘ç¬”çš„åŠ›åº¦å¯¹æ¯”
        # æ‰¾åˆ°æœ€è¿‘ä¸¤æ®µåŒå‘ç¬”
        last_bi = recent_bis[-1]
        
        # æ‰¾å‰ä¸€æ®µåŒå‘ç¬”
        prev_same_dir_bi = None
        for bi in reversed(recent_bis[:-1]):
            if bi.direction == last_bi.direction:
                prev_same_dir_bi = bi
                break
        
        if prev_same_dir_bi is None:
            return BeiChiType.NONE, "æœªæ‰¾åˆ°åŒå‘ç¬”ï¼Œæ— æ³•åˆ¤æ–­èƒŒé©°", False
        
        # è®¡ç®—åŠ›åº¦å¯¹æ¯”
        power_ratio = last_bi.power / prev_same_dir_bi.power if prev_same_dir_bi.power > 0 else 1
        
        macd_div = False
        
        if power_ratio < 0.618:  # é»„é‡‘åˆ†å‰²ç‚¹
            macd_div = True
            if last_bi.direction == BiDirection.DOWN:
                # ä¸‹è·ŒèƒŒé©° = åº•èƒŒé©° = ä¹°å…¥æœºä¼š
                return (
                    BeiChiType.TREND_BEICHI,
                    f"åº•èƒŒé©°ï¼šä¸‹è·ŒåŠ›åº¦å‡å¼±è‡³å‰æ®µçš„{power_ratio:.1%}ï¼Œå¤šå¤´å³å°†åæ”»",
                    macd_div
                )
            else:
                # ä¸Šæ¶¨èƒŒé©° = é¡¶èƒŒé©° = å–å‡ºä¿¡å·
                return (
                    BeiChiType.TREND_BEICHI,
                    f"é¡¶èƒŒé©°ï¼šä¸Šæ¶¨åŠ›åº¦å‡å¼±è‡³å‰æ®µçš„{power_ratio:.1%}ï¼Œç©ºå¤´å³å°†åæ”»",
                    macd_div
                )
        
        return BeiChiType.NONE, f"æœªå‡ºç°èƒŒé©°ï¼ŒåŠ›åº¦æ¯”{power_ratio:.1%}", False
    
    def _analyze_trend(
        self, 
        zhongshus: List[ZhongShu], 
        bis: List[Bi]
    ) -> Tuple[TrendType, str]:
        """åˆ†æè¶‹åŠ¿ç±»å‹"""
        if not zhongshus:
            if bis:
                # æ²¡æœ‰ä¸­æ¢ï¼Œçœ‹ç¬”çš„æ–¹å‘
                last_bi = bis[-1]
                if last_bi.direction == BiDirection.UP:
                    return TrendType.UP_TREND, "æ— ä¸­æ¢ï¼Œå½“å‰å¤„äºä¸Šå‡ç¬”ä¸­"
                else:
                    return TrendType.DOWN_TREND, "æ— ä¸­æ¢ï¼Œå½“å‰å¤„äºä¸‹é™ç¬”ä¸­"
            return TrendType.CONSOLIDATION, "æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ¤æ–­è¶‹åŠ¿"
        
        if len(zhongshus) == 1:
            return TrendType.CONSOLIDATION, f"å½¢æˆä¸€ä¸ªä¸­æ¢ï¼Œå¤„äºç›˜æ•´èµ°åŠ¿"
        
        # å¤šä¸ªä¸­æ¢ï¼Œæ¯”è¾ƒä¸­æ¢ä½ç½®
        last_zs = zhongshus[-1]
        prev_zs = zhongshus[-2]
        
        if last_zs.zd > prev_zs.zg:
            return TrendType.UP_TREND, f"ä¸­æ¢ä¾æ¬¡æŠ¬å‡ï¼Œä¸Šæ¶¨è¶‹åŠ¿æ˜ç¡®"
        elif last_zs.zg < prev_zs.zd:
            return TrendType.DOWN_TREND, f"ä¸­æ¢ä¾æ¬¡ä¸‹é™ï¼Œä¸‹è·Œè¶‹åŠ¿æ˜ç¡®"
        else:
            return TrendType.CONSOLIDATION, f"ä¸­æ¢é‡å ï¼Œå¤§çº§åˆ«ç›˜æ•´"
    
    def _identify_buy_sell_point(
        self, 
        result: ChanAnalysisResult,
        df: pd.DataFrame
    ) -> Tuple[BuySellPoint, str]:
        """
        è¯†åˆ«ä¹°å–ç‚¹
        
        ä¸€ä¹°ï¼šä¸‹è·Œè¶‹åŠ¿èƒŒé©°å
        äºŒä¹°ï¼šä¸€ä¹°åå›è¸©ä¸ç ´ä½ç‚¹
        ä¸‰ä¹°ï¼šç¦»å¼€ä¸­æ¢åå›è¸©ä¸è¿›ä¸­æ¢
        """
        current_price = float(df.iloc[-1]['close'])
        
        # æ£€æŸ¥æ˜¯å¦æœ‰èƒŒé©°
        if result.beichi_type != BeiChiType.NONE:
            if result.last_bi and result.last_bi.direction == BiDirection.DOWN:
                # åº•èƒŒé©° = ä¸€ä¹°
                return BuySellPoint.BUY_1, "å‡ºç°åº•èƒŒé©°ï¼Œå½¢æˆç¬¬ä¸€ç±»ä¹°ç‚¹"
            elif result.last_bi and result.last_bi.direction == BiDirection.UP:
                # é¡¶èƒŒé©° = ä¸€å–
                return BuySellPoint.SELL_1, "å‡ºç°é¡¶èƒŒé©°ï¼Œå½¢æˆç¬¬ä¸€ç±»å–ç‚¹"
        
        # æ£€æŸ¥ä¸‰ä¹°ä¸‰å–
        if result.current_zhongshu:
            zs = result.current_zhongshu
            
            # ä»·æ ¼åœ¨ä¸­æ¢ä¸Šæ–¹ï¼Œä¸”æœ€è¿‘æ˜¯å›è¸©
            if current_price > zs.zg:
                if result.last_bi and result.last_bi.direction == BiDirection.DOWN:
                    if result.last_bi.low > zs.zg:
                        return BuySellPoint.BUY_3, f"ç¦»å¼€ä¸­æ¢åå›è¸©ï¼Œä½ç‚¹{result.last_bi.low:.2f}åœ¨ä¸­æ¢ä¸Šæ²¿{zs.zg:.2f}ä¸Šæ–¹ï¼Œå½¢æˆä¸‰ä¹°"
            
            # ä»·æ ¼åœ¨ä¸­æ¢ä¸‹æ–¹ï¼Œä¸”æœ€è¿‘æ˜¯åå¼¹
            elif current_price < zs.zd:
                if result.last_bi and result.last_bi.direction == BiDirection.UP:
                    if result.last_bi.high < zs.zd:
                        return BuySellPoint.SELL_3, f"ç¦»å¼€ä¸­æ¢ååå¼¹ï¼Œé«˜ç‚¹{result.last_bi.high:.2f}åœ¨ä¸­æ¢ä¸‹æ²¿{zs.zd:.2f}ä¸‹æ–¹ï¼Œå½¢æˆä¸‰å–"
        
        # æ£€æŸ¥äºŒä¹°äºŒå–ï¼ˆéœ€è¦å‚è€ƒå‰ä¸€æ¬¡ä¹°å–ç‚¹ï¼‰
        if len(result.bis) >= 4 and result.last_fenxing:
            # ç®€åŒ–ç‰ˆï¼šå¦‚æœæœ€è¿‘åº•åˆ†å‹ä¸åˆ›æ–°ä½ï¼Œå¯èƒ½æ˜¯äºŒä¹°
            if result.last_fenxing.type == FenXingType.BOTTOM:
                prev_bottoms = [fx for fx in result.fenxings if fx.type == FenXingType.BOTTOM]
                if len(prev_bottoms) >= 2:
                    if result.last_fenxing.low > prev_bottoms[-2].low:
                        return BuySellPoint.BUY_2, f"å›è¸©ä½ç‚¹{result.last_fenxing.low:.2f}æœªç ´å‰ä½{prev_bottoms[-2].low:.2f}ï¼Œå½¢æˆäºŒä¹°"
            
            elif result.last_fenxing.type == FenXingType.TOP:
                prev_tops = [fx for fx in result.fenxings if fx.type == FenXingType.TOP]
                if len(prev_tops) >= 2:
                    if result.last_fenxing.high < prev_tops[-2].high:
                        return BuySellPoint.SELL_2, f"åå¼¹é«˜ç‚¹{result.last_fenxing.high:.2f}æœªç ´å‰é«˜{prev_tops[-2].high:.2f}ï¼Œå½¢æˆäºŒå–"
        
        return BuySellPoint.NONE, "å½“å‰æ— æ˜ç¡®ä¹°å–ç‚¹"
    
    def _calculate_key_levels(
        self, 
        result: ChanAnalysisResult,
        df: pd.DataFrame
    ) -> Dict[str, float]:
        """è®¡ç®—å…³é”®ç‚¹ä½"""
        levels = {}
        current_price = float(df.iloc[-1]['close'])
        levels['current_price'] = current_price
        
        # ä¸­æ¢ç‚¹ä½
        if result.current_zhongshu:
            zs = result.current_zhongshu
            levels['zhongshu_zg'] = zs.zg
            levels['zhongshu_zd'] = zs.zd
            levels['zhongshu_gg'] = zs.gg
            levels['zhongshu_dd'] = zs.dd
        
        # æœ€è¿‘åˆ†å‹ç‚¹ä½
        if result.fenxings:
            recent_tops = [fx for fx in result.fenxings[-10:] if fx.type == FenXingType.TOP]
            recent_bottoms = [fx for fx in result.fenxings[-10:] if fx.type == FenXingType.BOTTOM]
            
            if recent_tops:
                levels['recent_top'] = max(fx.high for fx in recent_tops)
            if recent_bottoms:
                levels['recent_bottom'] = min(fx.low for fx in recent_bottoms)
        
        # å»ºè®®ç‚¹ä½
        if result.buy_sell_point in [BuySellPoint.BUY_1, BuySellPoint.BUY_2, BuySellPoint.BUY_3]:
            # ä¹°å…¥å»ºè®®
            if result.current_zhongshu:
                levels['stop_loss'] = result.current_zhongshu.zd * 0.97  # ä¸­æ¢ä¸‹æ²¿ä¸‹æ–¹3%
            elif result.last_bi:
                levels['stop_loss'] = result.last_bi.low * 0.97
            
            if 'recent_top' in levels:
                levels['target'] = levels['recent_top']
        
        elif result.buy_sell_point in [BuySellPoint.SELL_1, BuySellPoint.SELL_2, BuySellPoint.SELL_3]:
            # å–å‡ºå»ºè®®
            if result.current_zhongshu:
                levels['stop_loss'] = result.current_zhongshu.zg * 1.03
            elif result.last_bi:
                levels['stop_loss'] = result.last_bi.high * 1.03
            
            if 'recent_bottom' in levels:
                levels['target'] = levels['recent_bottom']
        
        return levels
    
    def _calculate_score(self, result: ChanAnalysisResult) -> int:
        """
        è®¡ç®—ç¼ è®ºè¯„åˆ†
        
        è¯„åˆ†ç»´åº¦ï¼š
        1. è¶‹åŠ¿æ–¹å‘ï¼ˆ30åˆ†ï¼‰
        2. ä¹°å–ç‚¹ä¿¡å·ï¼ˆ30åˆ†ï¼‰
        3. èƒŒé©°ä¿¡å·ï¼ˆ20åˆ†ï¼‰
        4. ä¸­æ¢ä½ç½®ï¼ˆ20åˆ†ï¼‰
        """
        score = 50  # åŸºç¡€åˆ†
        
        # 1. è¶‹åŠ¿æ–¹å‘ï¼ˆ30åˆ†ï¼‰
        if result.trend_type == TrendType.UP_TREND:
            score += 15
        elif result.trend_type == TrendType.DOWN_TREND:
            score -= 15
        
        # 2. ä¹°å–ç‚¹ä¿¡å·ï¼ˆ30åˆ†ï¼‰
        if result.buy_sell_point in [BuySellPoint.BUY_1, BuySellPoint.BUY_2, BuySellPoint.BUY_3]:
            if result.buy_sell_point == BuySellPoint.BUY_1:
                score += 25  # ä¸€ä¹°æœ€å¼º
            elif result.buy_sell_point == BuySellPoint.BUY_3:
                score += 20  # ä¸‰ä¹°æ¬¡ä¹‹
            else:
                score += 15  # äºŒä¹°
        elif result.buy_sell_point in [BuySellPoint.SELL_1, BuySellPoint.SELL_2, BuySellPoint.SELL_3]:
            if result.buy_sell_point == BuySellPoint.SELL_1:
                score -= 25
            elif result.buy_sell_point == BuySellPoint.SELL_3:
                score -= 20
            else:
                score -= 15
        
        # 3. èƒŒé©°ä¿¡å·ï¼ˆ20åˆ†ï¼‰
        if result.beichi_type != BeiChiType.NONE:
            if result.last_bi and result.last_bi.direction == BiDirection.DOWN:
                score += 15  # åº•èƒŒé©°åŠ åˆ†
            else:
                score -= 15  # é¡¶èƒŒé©°å‡åˆ†
        
        # 4. ä¸­æ¢ä½ç½®ï¼ˆ20åˆ†ï¼‰
        if result.current_zhongshu and result.key_levels.get('current_price'):
            price = result.key_levels['current_price']
            zs = result.current_zhongshu
            
            if price > zs.zg:
                score += 10  # åœ¨ä¸­æ¢ä¸Šæ–¹
            elif price < zs.zd:
                score -= 10  # åœ¨ä¸­æ¢ä¸‹æ–¹
        
        return max(0, min(100, score))
    
    def _generate_suggestion(self, result: ChanAnalysisResult) -> str:
        """ç”Ÿæˆæ“ä½œå»ºè®®"""
        if result.chan_score >= 80:
            return "å¼ºçƒˆä¹°å…¥ï¼šç¼ è®ºå¤šé‡ä¿¡å·å…±æŒ¯ï¼Œè¶‹åŠ¿å‘ä¸Š"
        elif result.chan_score >= 65:
            return "ä¹°å…¥ï¼šç¼ è®ºä¿¡å·ç§¯æï¼Œå¯é€¢ä½å¸ƒå±€"
        elif result.chan_score >= 50:
            return "è§‚æœ›ï¼šä¸­æ¢éœ‡è¡ä¸­ï¼Œç­‰å¾…æ–¹å‘æ˜ç¡®"
        elif result.chan_score >= 35:
            return "å‡ä»“ï¼šç¼ è®ºä¿¡å·è½¬å¼±ï¼Œæ³¨æ„é£é™©"
        else:
            return "å–å‡ºï¼šç¼ è®ºä¿¡å·çœ‹ç©ºï¼Œå»ºè®®ç¦»åœº"
    
    def _summarize_fenxings(self, fenxings: List[FenXing]) -> str:
        """åˆ†å‹æ‘˜è¦"""
        if not fenxings:
            return "æ— æœ‰æ•ˆåˆ†å‹"
        
        tops = sum(1 for fx in fenxings if fx.type == FenXingType.TOP)
        bottoms = sum(1 for fx in fenxings if fx.type == FenXingType.BOTTOM)
        last_fx = fenxings[-1]
        
        return f"å…±{len(fenxings)}ä¸ªåˆ†å‹ï¼ˆé¡¶{tops}/åº•{bottoms}ï¼‰ï¼Œæœ€è¿‘ä¸º{last_fx.type.value}ï¼ˆ{last_fx.date}ï¼‰"
    
    def _summarize_bis(self, bis: List[Bi]) -> str:
        """ç¬”æ‘˜è¦"""
        if not bis:
            return "æ— æœ‰æ•ˆç¬”"
        
        up_bis = sum(1 for bi in bis if bi.direction == BiDirection.UP)
        down_bis = len(bis) - up_bis
        last_bi = bis[-1]
        
        return f"å…±{len(bis)}ç¬”ï¼ˆä¸Šå‡{up_bis}/ä¸‹é™{down_bis}ï¼‰ï¼Œå½“å‰{last_bi.direction.value}"
    
    def _summarize_xianduans(self, xianduans: List[XianDuan]) -> str:
        """çº¿æ®µæ‘˜è¦"""
        if not xianduans:
            return "æ— æœ‰æ•ˆçº¿æ®µ"
        
        last_xd = xianduans[-1]
        return f"å…±{len(xianduans)}æ®µï¼Œå½“å‰{last_xd.direction.value}ï¼ˆé«˜{last_xd.high:.2f}/ä½{last_xd.low:.2f}ï¼‰"
    
    def _summarize_zhongshu(self, zs: ZhongShu, price: float) -> str:
        """ä¸­æ¢æ‘˜è¦"""
        position = self._get_price_position(price, zs)
        return f"ä¸­æ¢åŒºé—´ [{zs.zd:.2f}, {zs.zg:.2f}]ï¼Œå½“å‰ä»·æ ¼{position}"
    
    def _generate_summary(self, result: ChanAnalysisResult) -> str:
        """ç”Ÿæˆç»¼åˆåˆ†ææ‘˜è¦"""
        parts = []
        
        # è¶‹åŠ¿åˆ¤æ–­
        parts.append(f"ã€è¶‹åŠ¿ã€‘{result.trend_type.value}ï¼š{result.trend_summary}")
        
        # ä¸­æ¢ä½ç½®
        if result.current_zhongshu:
            parts.append(f"ã€ä¸­æ¢ã€‘{result.zhongshu_summary}")
        
        # èƒŒé©°ä¿¡å·
        if result.beichi_type != BeiChiType.NONE:
            parts.append(f"ã€èƒŒé©°ã€‘{result.beichi_summary}")
        
        # ä¹°å–ç‚¹
        if result.buy_sell_point != BuySellPoint.NONE:
            parts.append(f"ã€ä¿¡å·ã€‘{result.buy_sell_point.value}ï¼š{result.buy_sell_reason}")
        
        # å…³é”®ç‚¹ä½
        levels = result.key_levels
        if 'zhongshu_zg' in levels:
            parts.append(f"ã€ç‚¹ä½ã€‘ä¸­æ¢ä¸Šæ²¿{levels['zhongshu_zg']:.2f}ï¼Œä¸­æ¢ä¸‹æ²¿{levels['zhongshu_zd']:.2f}")
        if 'stop_loss' in levels:
            parts.append(f"ã€æ­¢æŸã€‘{levels['stop_loss']:.2f}")
        
        return "\n".join(parts)
    
    def format_analysis(self, result: ChanAnalysisResult) -> str:
        """
        æ ¼å¼åŒ–åˆ†æç»“æœä¸ºæ–‡æœ¬
        
        Args:
            result: åˆ†æç»“æœ
            
        Returns:
            æ ¼å¼åŒ–çš„åˆ†ææ–‡æœ¬
        """
        lines = [
            f"=== {result.code} ç¼ è®ºåˆ†æ ===",
            f"",
            f"ğŸ“Š ç¼ è®ºè¯„åˆ†: {result.chan_score}/100",
            f"ğŸ¯ æ“ä½œå»ºè®®: {result.operation_suggestion}",
            f"",
            f"ğŸ“ˆ è¶‹åŠ¿åˆ¤æ–­: {result.trend_type.value}",
            f"   {result.trend_summary}",
            f"",
            f"ğŸ” åˆ†å‹: {result.fenxing_summary}",
            f"ğŸ“ ç¬”: {result.bi_summary}",
            f"ğŸ“ çº¿æ®µ: {result.xianduan_summary}",
            f"",
        ]
        
        if result.current_zhongshu:
            lines.extend([
                f"ğŸ¯ ä¸­æ¢åˆ†æ:",
                f"   {result.zhongshu_summary}",
                f"   ä»·æ ¼ä½ç½®: {result.price_position}",
                f"",
            ])
        
        if result.beichi_type != BeiChiType.NONE:
            lines.extend([
                f"âš¡ èƒŒé©°ä¿¡å·:",
                f"   ç±»å‹: {result.beichi_type.value}",
                f"   {result.beichi_summary}",
                f"",
            ])
        
        if result.buy_sell_point != BuySellPoint.NONE:
            lines.extend([
                f"ğŸ’¡ ä¹°å–ç‚¹:",
                f"   ä¿¡å·: {result.buy_sell_point.value}",
                f"   {result.buy_sell_reason}",
                f"",
            ])
        
        # å…³é”®ç‚¹ä½
        levels = result.key_levels
        if levels:
            lines.append(f"ğŸ“ å…³é”®ç‚¹ä½:")
            if 'current_price' in levels:
                lines.append(f"   å½“å‰ä»·æ ¼: {levels['current_price']:.2f}")
            if 'zhongshu_zg' in levels:
                lines.append(f"   ä¸­æ¢ä¸Šæ²¿: {levels['zhongshu_zg']:.2f}")
            if 'zhongshu_zd' in levels:
                lines.append(f"   ä¸­æ¢ä¸‹æ²¿: {levels['zhongshu_zd']:.2f}")
            if 'stop_loss' in levels:
                lines.append(f"   å»ºè®®æ­¢æŸ: {levels['stop_loss']:.2f}")
            if 'target' in levels:
                lines.append(f"   ç›®æ ‡ä½: {levels['target']:.2f}")
        
        return "\n".join(lines)


def analyze_chan(df: pd.DataFrame, code: str) -> ChanAnalysisResult:
    """
    ä¾¿æ·å‡½æ•°ï¼šç¼ è®ºåˆ†æ
    
    Args:
        df: åŒ…å« OHLCV æ•°æ®çš„ DataFrame
        code: è‚¡ç¥¨ä»£ç 
        
    Returns:
        ChanAnalysisResult åˆ†æç»“æœ
    """
    analyzer = ChanAnalyzer()
    return analyzer.analyze(df, code)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)
    
    # æ¨¡æ‹Ÿæ•°æ®æµ‹è¯•
    import numpy as np
    
    dates = pd.date_range(start='2025-01-01', periods=60, freq='D')
    np.random.seed(42)
    
    # æ¨¡æ‹Ÿä¸€ä¸ªæœ‰æ³¢åŠ¨çš„è¡Œæƒ…
    base_price = 10.0
    prices = [base_price]
    for i in range(59):
        # æ·»åŠ è¶‹åŠ¿å’Œæ³¢åŠ¨
        trend = 0.001 * np.sin(i / 10)  # å‘¨æœŸæ€§è¶‹åŠ¿
        noise = np.random.randn() * 0.03
        change = trend + noise
        prices.append(prices[-1] * (1 + change))
    
    df = pd.DataFrame({
        'date': dates,
        'open': [p * (1 - np.random.uniform(0, 0.01)) for p in prices],
        'high': [p * (1 + np.random.uniform(0, 0.03)) for p in prices],
        'low': [p * (1 - np.random.uniform(0, 0.03)) for p in prices],
        'close': prices,
        'volume': [np.random.randint(1000000, 5000000) for _ in prices],
    })
    
    analyzer = ChanAnalyzer()
    result = analyzer.analyze(df, '000001')
    print(analyzer.format_analysis(result))
    print("\n" + "="*50)
    print("Result Dict:")
    for k, v in result.to_dict().items():
        print(f"  {k}: {v}")
